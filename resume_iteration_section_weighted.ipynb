{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        text = \" \".join(page.extract_text() or \"\" for page in reader.pages)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sections(text):\n",
    "    sections = {\n",
    "        \"skills\": \"\",\n",
    "        \"experience\": \"\",\n",
    "        \"projects\": \"\",\n",
    "        \"other\": \"\"\n",
    "    }\n",
    "    current = \"other\"\n",
    "    for line in text.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        l = line.lower()\n",
    "        if \"skill\" in l:\n",
    "            current = \"skills\"\n",
    "        elif \"experience\" in l:\n",
    "            current = \"experience\"\n",
    "        elif \"project\" in l:\n",
    "            current = \"projects\"\n",
    "        sections[current] += line + \" \"\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_score(resume_sections, jd_text):\n",
    "    jd_emb = model.encode(jd_text, convert_to_tensor=True)\n",
    "    weights = {\n",
    "        \"skills\": 0.1,\n",
    "        \"experience\": 0.6,\n",
    "        \"projects\": 0.3\n",
    "    }\n",
    "\n",
    "    score = 0.0\n",
    "    for sec, text in resume_sections.items():\n",
    "        if text.strip() == \"\":\n",
    "            continue\n",
    "        emb = model.encode(text, convert_to_tensor=True)\n",
    "        sim = util.pytorch_cos_sim(emb, jd_emb).item()\n",
    "        score += weights.get(sec, 0.0) * sim\n",
    "    return round(score * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dir = \"resumes/\"\n",
    "# jd_path = \"JDs/AI_intern_Armada.txt\"\n",
    "jd_path = \"JDs/Data_engineering_intern_LiveRamp.txt\"\n",
    "\n",
    "with open(jd_path, 'r', encoding='utf-8') as f:\n",
    "    jd_text = f.read()\n",
    "\n",
    "results = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(resume_dir):\n",
    "    if not file.endswith(\".pdf\"):\n",
    "        continue\n",
    "    fpath = os.path.join(resume_dir, file)\n",
    "    text = extract_text_from_pdf(fpath)\n",
    "    sections = extract_sections(text)\n",
    "    score = weighted_score(sections, jd_text)\n",
    "    results.append({\"Resume\": file, \"Weighted Score\": score})\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"Weighted Score\", ascending=False)\n",
    "results_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume</th>\n",
       "      <th>Weighted Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dhruvraj_resume_May18.pdf</td>\n",
       "      <td>42.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dhruvraj_resume_MSDS.pdf</td>\n",
       "      <td>42.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dhruvraj_resume_USHunger.pdf</td>\n",
       "      <td>38.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dhruvraj_resume_Mar11.pdf</td>\n",
       "      <td>38.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dhruvraj_Resume_intern_rocket.pdf</td>\n",
       "      <td>38.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dhruvraj_resume_image_analytics.pdf</td>\n",
       "      <td>8.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Resume  Weighted Score\n",
       "0            Dhruvraj_resume_May18.pdf           42.59\n",
       "1             Dhruvraj_resume_MSDS.pdf           42.23\n",
       "2         Dhruvraj_resume_USHunger.pdf           38.99\n",
       "3            Dhruvraj_resume_Mar11.pdf           38.17\n",
       "4    Dhruvraj_Resume_intern_rocket.pdf           38.17\n",
       "5  Dhruvraj_resume_image_analytics.pdf            8.08"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## latest\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from math import ceil\n",
    "\n",
    "def summarize_batch_with_ollama(jd_text, resume_batch):\n",
    "    batch_prompts = \"\"\n",
    "    for idx, resume_text in enumerate(resume_batch, start=1):\n",
    "        batch_prompts += f\"\\nResume {idx}:\\n\\\"\\\"\\\"{resume_text[:2000]}\\\"\\\"\\\"\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant helping recruiters evaluate candidates by comparing their resumes with a job description. For each resume, provide:\n",
    "\n",
    "1. A 40-word summary of how the resume aligns with the JD.\n",
    "2. A bullet list of 5 key relevant skills.\n",
    "3. A one-line highlight of the candidate’s relevant experience.\n",
    "\n",
    "Job Description:\n",
    "\\\"\\\"\\\"{jd_text}\\\"\\\"\\\"\n",
    "\n",
    "{batch_prompts}\n",
    "\n",
    "Format output as:\n",
    "\n",
    "Resume 1:\n",
    "Summary: ...\n",
    "Relevant Skills:\n",
    "- ...\n",
    "Main Highlight: ...\n",
    "\n",
    "Resume 2:\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='llama3.2',\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response['message']['content'].strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_resumes_ollama(jd_text, resume_texts, output_path=\"resume_summaries.txt\"):\n",
    "    batch_size = 3\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, len(resume_texts), batch_size):\n",
    "        batch = resume_texts[i:i+batch_size]\n",
    "        result = summarize_batch_with_ollama(jd_text, batch)\n",
    "        results.append(result)\n",
    "\n",
    "    all_summary_text = \"\\n\\n\".join(results)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(all_summary_text)\n",
    "\n",
    "    print(f\"✅ Summaries saved to {output_path}\")\n",
    "    return all_summary_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Summaries saved to summary_ollama_output.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Here is the evaluation of the three resumes against the job description:\\n\\n**Resume 1**\\n\\nSummary: The resume aligns with the JD as it showcases Dhruvraj's experience in data pipeline development, ETL processes, and analytics solutions. The candidate has worked on various projects that demonstrate their proficiency in Python, SQL, and big data tools.\\n\\nRelevant Skills:\\n- Data pipeline development\\n- ETL processes\\n- Analytics solutions\\n- Big data tools (PySpark, Hadoop, Kafka)\\n- Cloud computing (AWS Suite)\\n\\nMain Highlight: Dhruvraj's experience as a Data Analyst at Draup Business Solutions Bangalore, where he designed and deployed high-performance ETL pipelines using PySpark and SQL on AWS EMR, improving data integrity by 35%.\\n\\n**Resume 2**\\n\\nSummary: The resume aligns with the JD as it highlights Dhruvraj's expertise in machine learning, deep learning, and big data. The candidate has worked on various projects that demonstrate their proficiency in machine learning frameworks like Scikit-learn, TensorFlow, and PyTorch.\\n\\nRelevant Skills:\\n- Machine learning\\n- Deep learning\\n- Big data tools (Spark, Hadoop, Kafka)\\n- ETL automation pipelines\\n- Data visualization\\n\\nMain Highlight: Dhruvraj's experience working on a personalized research assistant project using RAG and LangChain, which demonstrates their ability to build AI applications.\\n\\n**Resume 3**\\n\\nSummary: The resume aligns with the JD as it showcases Dhruvraj's experience in data analysis, ETL processes, and analytics solutions. The candidate has worked on various projects that demonstrate their proficiency in Python, SAS, and big data tools.\\n\\nRelevant Skills:\\n- Data analysis\\n- ETL processes\\n- Analytics solutions\\n- Big data tools (PySpark, SQL)\\n- Cloud computing (AWS Suite)\\n\\nMain Highlight: Dhruvraj's experience as a Student Research Assistant at Texas A&M University College Station, where they conducted statistical analysis on Medicaid data using Python and SAS.\\n\\nHere are the outputs for each resume:\\n\\n\\nResume 1:\\nSummary: Aligns with JD requirements in data analysis, ETL processes, and data visualization, showcasing proficiency in Python, SQL, and big data tools like PySpark.\\n\\nRelevant Skills:\\n- Data validation frameworks\\n- ETL processes\\n- Big data tools (PySpark)\\n- Data mining and wrangling pipelines\\n- Dashboard development\\n\\nMain Highlight: Implemented scalable and robust ETL data validation frameworks utilizing PySpark and SQL, resulting in a 35% improvement in end-to-end data integrity.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_paths = [\n",
    "    \"resumes/Dhruvraj_resume_May18.pdf\",\n",
    "    \"resumes/Dhruvraj_resume_MSDS.pdf\",\n",
    "    \"resumes/Dhruvraj_resume_USHunger.pdf\",\n",
    "    \"resumes/Dhruvraj_Resume_intern_rocket.pdf\"\n",
    "]\n",
    "\n",
    "resume_texts = [extract_text_from_pdf(path) for path in resume_paths]\n",
    "jd_text = open(\"JDs/Data_engineering_intern_LiveRamp.txt\", \"r\", encoding=\"utf-8\").read()\n",
    "\n",
    "summarize_resumes_ollama(jd_text, resume_texts, \"summary_ollama_output.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
