Data & Analytics Engineering Intern LiveRamp is the data collaboration platform of choice for the world’s most innovative companies. A groundbreaking leader in consumer privacy, data ethics, and foundational identity, LiveRamp is setting the new standard for building a connected customer view with unmatched clarity and context while protecting precious brand and consumer trust. LiveRamp offers complete flexibility to collaborate wherever data lives to support the widest range of data collaboration use cases—within organizations, between brands, and across its premier global network of top-quality partners. Hundreds of global innovators, from iconic consumer brands and tech giants to banks, retailers, and healthcare leaders turn to 

LiveRamp to build enduring brand and business value by deepening customer engagement and loyalty, activating new partnerships, and maximizing the value of their first-party data while staying on the forefront of rapidly evolving compliance and privacy requirements. LiveRamp is looking for a Data & Analytics Engineering Intern to join our growing data team. In this role, you will work on designing and optimizing data pipelines, enabling analytics solutions, and contributing to LiveRamp’s data infrastructure. You will collaborate with engineers, analysts, and business teams to transform raw data into actionable insights. This internship is ideal for students who are passionate about data engineering, analytics, and solving complex problems with data-driven solutions. 

You will:
1. Assist in developing, maintaining, and optimizing data pipelines and data platforms. 
2. Collaborate with the engineering team to build and enhance data models and ETL processes. 
3. Support the design and implementation of analytics dashboards and reporting tools. 
4. Work with cross-functional teams to understand business requirements and translate them into technical solutions. 
5. Explore new technologies and tools to improve data processing and analytics capabilities. 
6. Contribute to data quality initiatives by monitoring and ensuring the integrity of data across systems. 

About you: 
1. Currently pursuing a Bachelor’s or Master’s degree in Computer Science, Data Engineering, Analytics, or a related field. Proficiency in Python and SQL for data processing and analysis. 
2. Strong understanding of data modeling, ETL concepts, and database systems (relational and non-relational). 
3. Excellent problem-solving skills, analytical mindset, and attention to detail. Ability to work collaboratively in a fast-paced, team-oriented environment. 
4. Experience with big data tools (such as Spark, Hadoop, or Kafka) is a plus but not required.